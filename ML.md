Препод: Андрей Фильченков - основной

В конце экзамен: два теор. вопроса + задача на 5

Для допуска нужно садать часть лаб и пройти тесты в начале лекций.

Текстовый вариант лекций: буст к оценке.

Обычно лекция+ практика




**Лекция 1:**

Есть разные определение для маш. обучения.


  * Машинное обучение это процесс, обучения знаниям, которым он не был до этого явно запрограммирован.
    * (не формальное и расплывчатое. Можно трактовать как широкое и как узкое) 1959 год.
  * Компьютерная программа обучается с опытом Е относительно задаче Т с мерой эффективности Р,  если её эффективность Т, измерямое Р, улучшается с опытом Е.
    * слижком узкое - не все задачи по маш. обучению можно можно так формализовать. Не всегда можно выделить меру
   * Программа Машинно Обучается, если пытается улучшать своё поведение.


Генетический Алгоритмы - но МО не являются.

Нейтронные сети - сложно связаны с МО.
МО - важно. Появляется почти в любой крупной компании. 

Примеры: 2гис с обучением выдаёт местоположение, кинопоиск рекомендует фильмы, транслейт переводит, гугл выдаёт поиск. Всё с помощью МО. 

Применение: Обработка изображений, диагностика, медицина..


  * МО
    * Распознование образов 
      * Теперь подобраз МО
      * Есть разница подходов 
    * Компьютерное зрение
      * Долго было не связано с МО, а с робототехникой
      * Большой пласт знаний как из информации получать что-то связное
      * Всё равно в основе это было МО
    * Data Mining (Анализ данных)
      * АД мало различают с МО 
      * МО примерно про алгоритма, а АД про задачи
      * МО Более абстрактно, а АД связано с конкретными областями
      * Есть мнение что АД  что мало связано с МО, но это не то, чего мы будем придерживаться
    * NLP (Natural language processing)
    * Извлечение информации
      * Представление информации о чём-то кем-то в соц сети, 
    * Нейоронные Вычисления (Нейронные Сети, НС)
      * Отдельностоящая наука сильно пересекающаяся с МО.
      * Глубокие нейронные сети - большие нейронные сети, с огромным количеством слоёв. 

    



  * Стек абстракции:
    * Алгоритмы
    * МО
    * Анализ данных (АД)
    * Извлечение Информации 
    * Данные


Связь с другими областями:

  * Сязь с ИИ (Искуственный Интеллект)
    * в 60х годах думали что задачи ИИ можно будет решить как создание программ. 
    * 59 в ходе летнего семинара светила  науки попытались придумать ИИ, но ничего не вышло - задача была сильно сложнее, чем они думаем.
    * Сильный ИИ - система в некотором смысле не отличима / не хуже человека. (Тест Тюринга, но это ооочень спорный критерий)
    * Слабый ИИ -  Узкоспецифицированая программа, умеющая решать некоторую задачу лучше человека (отличать зайчиков от котиков, например)
    * Слабый и Сильный ИИ разошлись в путях, но их сейчас пытаются объеденить с помощью НС
    * Всё что мы будем обсуждать, связано Слабым ИИ.
  * ИС
    * Поспрашиваем людей, от них получим правила и на основе их построим систему решающую узкую задачу.
    * Если мало ресурсов и времени, то приходится не обучать, и заменять часть обучения эмпириками и данными которые есть.
    * Пример: в будущем с помощью МО можно просто скармливать тексты системе, и она будем ему обучатся, находить зависимости выводить грамматику. Сейчас же - приходится нужно в ручную забивать модель языка, т.к. ресурсов мало.
    * ИС сильно связаны с медициной. Пример: спрашиваем терапевта о соответствии симптомов и болезни, формализуем, забиваем эвристики в программу, пробуем с помощью программы определять болезнь.
    * Стаорые системы ещё крутятся, но новые ИС практически не разрабатваются, т.к. проще обучить. 
  * Математические модели
    * Берём математические модели описанные учёными, и используем их.




Данные - более не понятное как человеку, часто представляемые базами данных, есть другие способы представления данных, но их так базами данных и называютс. 




   * Данные не знания!
     * Знания - принципы, паттерны, закономерности 
     * Знания - шаблоны, в определённой области (принцыпы, зависимости, отношения, правила, законы), полученные с помощью практики и профессионального опыта., которые помогают формулировать и решать проблемы


  * Стек абстраккции- ниже абстрактнее
    * Эксперты
      * данные извлекаются из экспервтов
    * Мат. Модели
    * МО
    * ГНС

  * Что нужно для обучения МО:
    * Теория Вероятности и Мат. Стат.
      * Много представляется в вероятностной модели, т.к. это хороший способ 
    * Оптимизационные задачи
      * Есть целевая функция F: X-&gt;**R **
      * Есть функция ограничения f, g_i: X-&gt;**R**
      * Constr = { g_i(x) &lt;= 0}
      * Область - нужно найти максимум или минимум на области.
      * Есть:
        * Аналитические
          * с помощью производных
        * Вычислительные
          * Метод Ньютона
      * Информатика
      * Теория сложности
      * Линейная алгебра
        * данные часто представляются матрицами
        * Традиционная форма в задачах класификаиции
        * След, обратные, собственные
      * Дискретная Математика
        * Многое представляется в виде графов
      * Иногда матан с функаном
  * Из чего состоит МО
    * Основные проблемы: (общепризнаных класификаций нет)
      * Обучение с учителем
        * Есть обучающая выборка, про которые мы знаем правильные ответ (есть лечение, и результат после него)
        * Подзадачи
          * Задачи класификации (разделение на конечное число классов)
          * Регрессии
          * Обучение рангам (разделение с выявленияеми связями)
          * ??
      * Обучение без учителя
        * Кластеризация
          * Есть данные, нужно разделить на части похожие по свойствам
          *

        * Поиск ассоциативным правилам
          * Поиск связей
        * Рекомендательные системы (обычно не выделяется)
        * Уменьшение разнести
      * Частичное обучение с учителем
        * Про некоторые данные знаем ответ 
      * Reinforcement learning
        * по действиям среды выработать оптимальную стратегию
      * Активное обучение
        * Программа спрашивает про что-то чтобы узнать больше
      * Онлайн обучение
        * Обучение на данных приходящих пачками, на которые нужно отдавать ответ на основе прошлых данных
      * Предсказание расписаний
      * Выбор модели и валидация
        * Сложный и менее прикладной

Будем заниматься алгоритмами обучения с и без учителя, а потом поговорим про выбор моделей




Большую часть времени будем заниматься задачей классификации. 

Для неё разработано множество техник. 


Почти все разработанные техники применяются много где. Почти любую задачу МО можно заменить задачей оптимизации. Важно не уметь решать конкретную, а понимать как решаются другие. 


  * Модель:

    * Х - множество объектов
    * У - множество меток/ответов
      * Пример: Х множество пациентов. У - есть грип или нет?
    * у:Х-&gt;У неизвестная целевая функция (зависимость)
    * {x_1, .. , x__L_} подмножество Х - обучающая выборка
    * у_i = y(x_i), i = 1 .. _L _Известные  ответы функции. 
    * Проблема: найти _a:_X -&gt; Y решающую функцию, приближающую y на Х. a - алгоритм, а значит он должен быть разрешим.
  * Основные вопросы:
    * Как описываются объекты?
      * Пример - пациенты описываются несколькими симптомами
        * Бинарные - (мальчик/девочки)
        * Категоричные - конечно (виды грипов, на каком континенте родился)
        * упорядоченные - конечно, упорядочено (виды грипов с летальность, возраст на классы(ребёнок, пожилой)))
        * числовой - ( в философском смысле всё конечно, но разделять всё на 2ККК классов не круто, лучше угадывать как числовой признак)
      * Данные описываются в виде таблички
        * есть функции f_i(x) выдающая признак i
        * все данные матрица |f_j(x_i)|
    * Как выглядят ответы?
      * Похожи на примеры, но могут отличаться.
        * Бинарные (есть-нет грипп)
        * не пересекающиеся классы
        * Пересекающуюся классы (можно разбить всё по пересечениям и получить прошлый вариант)
        * Ранги - ограниченная (частично) сортированое множесво
        * регрессии **R **или** R**^_m_
    * Какое множество алгоритмов, из которого выбирается _а_.
      * Вы востанавливаете не функцию, а функцию доступную вам. От способа зависит пространство функций, где будет ответ.
      * Модель алгоритмов - семейство отображений параметризованых алгоритмов.
        * Основной смысл - можно каждое решение представить в виде алгоритма и ложного параметра
    * Как обучаем?
      * mu: (X x Y)^_l -&gt; _A
      * Метода по обучающей выборке получающий алгоритм
      * Два Шага:
        * Тренировка
          *

        * Тестирование
          * Применяем полученные алгоритм к другим объектам
      * Пример: набольных преобразуя
    * Как определяем качество?
      * Чтобы понять стоило или нет, нам нужно понять насколько алгоритм плох. Вводим функцию потерь. Т.е. если алгоритм говорит что есть грип, когда его нет, насколько это плохо. Обычно при вправльном ответе - потеря 0, а если нет, то результаты разные:
        * Для класификации 1
        * Для регрессии разница
        * Квадаратичная функция потерь - используется в регрессиях 
      * Эмперический риск - среднее/мат. ожидание функции потерь на всех объектах обучащей выборки.
      * Функцию потерь стандартным способом не выбрать  - есть много рекомендаций, нужно использовать мозг.
    * Методы обучения:

      * Минимизация эмпирического риска:
        * Хотим найти алгоритм, на котором будет минимален эмперический риск на множестве.
        * Метод возвращает: x из T^l -&gt; Y(x), иначе rand
      * Проблема переобучения:
        * Чем лучше обучаемся на выборке, тем хуже получаем результаты на реальных объекта
        * Чем лучше модель береём, тем лучше подгоняемся под конкретные данные, и с определённого момента под шумы и погрешности - что портит результаты для реальных данных.
        * Решения: прекратить раскачивать хвост и переобучать
          * Обучаться на одной части набора, и тестироваться на другой
        * В реальности очень хорошо применять общине знания о мире, для понимания реальности решения 
  * Прмеры использования:

    * Медицина:
      * Болен или нет
      * Как лечить
      * предсказание последующих симптомов
      * Полезность лечения из ограничений (деньги, время)
        * Присзнаки этого:
          * Поведенческие (проблемы - все лгут, и что с этим делать?)
          * социо-демографические
    * Кредитный скоринг (свехрполулярная задача):
      * Давать или не давать, а если давать, то под какой процент и сколько
      * Модель постоянно меняется, нужно обучаться 
      * Когда именно вернёт деньги
      * Признаки:
        * Иерархия работы
        * Взятые кредиты
        * Недвижимость
        * история кредитов
    * Фильтрация спама
      * Несиметричность функции потерь 
        * цукерберг предложил работать - важно не назвать спамом
        * если увеличить палец на руках - не так страшно удалить
      * постоянно борьба спаммеров и фильтров
    * Категоризация документов:
      * есть статьи, нужно разделить на темы
      * Обычно ориентировались на слова, но модель ограниченная
      * Как раскидать по неизвестным категориям, и как их назвать
      * Понять является ли этот автор, автором этого текста
    * Оценка недвижимости
      * За сколько продавать
      * Признаки:
        * история
        * цена недавных соседних продаж
        * площадь комнаты - хорошо корелирует со стоимостью, а одтельно ширина и длинна хуже
        * наколько белый микрорайон (в США недавно)
    * Предсказание уровня продаж
      * Хотим спрогнозировать прибыль, оптимизировать её 
      * Сколько нужно товара хранить и закупать, по каким складам и когда распределять.
      * Не допускать недостатка товара на местах, вовремя подвозить
    * Ранжирование поисковой выдачи
      * милион ссылок на подобное
      * нужно множество эмпирик
        * количество ссылок 
        * Раньше сидели люди и оценивали выдачу
        * сейчас смотрят на поведение пользователей
        * мат. лингвиситка
        * Персонализация
    * Колобаротивная фильтрация
      * Куча товаров
      * Кому-что посоветовать
      * netflix предлагали гиганскую сумму за крутой способ предложений. Куча людей на них бесплатно работала.
    * Определение категорий пользователей
      * Пиво и памперсы часто покупают вместе
    * Оценка реальности подписи человека
      * задача с одним классом
      * специфичная - поиск аномалий
    * Предсказание бирживых индексов
      * есть групы которые торгуют
      * есть группы которые хорошую статью
      * группы мало пересекаются 
      * Очень-Очень много информации
      * Постоянно получается переобучение
    * Предсказание синтезирования лекарсв
      * Предсказание воздействия  химических соединений на инфекции

Основная книга: Хасти, тибшарани, фридман inteface and prediction




**Лекция 2: (метрические классификаторы)**

**
**

  * Утинный тест: если выглядит как утка, плавает как утка, крякаяет как утка, то наверное это утка.
    * На самом деле это описание алгоритма и алгоритма классификации.
    * Даже в некотором роде говорим о вероятностной классификации, то об этом позже.


  * Это алгоритм.
    * Была обучающаяя выборка: видели много утро
    * использовали признаки для обучения
    * использовали логические операции

такая простая идея лежит в основе метрических классификаторов
Главная гипотеза: похожие обьекты лежат тому же классу



Медики спользуют типичные методы, они видели много симптомов, болезней, и по ним пробуют определять болезнь.
Что-то случилось ищем похожий случай - если похож на утку, значит утка. По факту шага обучения не было - сравниваем с тем что запомнили.



Как определяем похожее? 
Формализуем концепт "похожести" вводя метрику
Часто дана метрика, но обычно дают обычные признаки, и их нужно перевести в метрики.
Если есть обоснованная функция расстояния, можно пробовать испольовать, судите по результатм. Исследования противоречивы на этот счёт.


Хорошо используетя метрические вариаци расстояния минковского.
Иногда используются расстояние Манхланоиса, если у нас нормальное, или приводимое к нему, распределение.


_1NN:_

Чтобы определять ближайшего соседа, разбиваем пространство на диаграму Воронова, а потом новые точки смотрим в какую ячейку попали.

Шум создаёт ячейку Воронова, которая является ошибочное.
Очень низкая точность, нет параметров(явных. можно менять метрику)

нужно хранить все объекты.


  * Что можно улучшить?
  * делаем более сложную конструкцию
  * менять пространство
    * уменьшать размерности, чтобы уменьшать влияние шумовых признаков
  * менять метрику
  * хорошо храним с помощью структурки
  * выкидывать плохие признаки, объекты от выкидвывания которых, результаты не улучшатся.
  * будем смотреть, не на ближайшего, а большее число соседей.
    * это будет уменьшать влияние шумов
    * сильное увеличение радиуса не даст многого. Нужно разумно.
    * можно смотреть по количесву соседей в радиусе
    * Чем больше ближайших соседей, тем более гладкая поверхность границ
  * ядра - симметричный, не отрицательны, интеграл равен 1
    * финитные (в какой-то момент были равны нулю (нормируем так, что =  0 в +- 1.

    * не финитые так не ограничиваем
  * Окно Парсена
    * берём фиксированую ширину окна, умножаем на функцию ядра от расстояния делённого на радиус.
    * берём сумму значимостей или произведений (другое сложно и обычно бессмысленно)
    * Если выборка не сильно плотная, то можно использовать радиус  - k+1 соседа (в радиусе будет k соседей всегда)
  * Hold-out
    * разобъём набор Train и на Test
    * на одной тренируемся, на другой треснемся
  * Cros-validation
    * разбиваем на k частей, k раз тренимся на всём, а на k-той части валидируемся
    * можно делать t раз, разбивая по разному (рандомно, но с сохранением пропорций исходнй выборки)
    * t = k = 10 рекомендация
  * Complete-cross-validation
    * тоже самое, только фиксируем пропорции, и разибваем всеми способами
    * используется, только оставляя в тестовой выборке один объект
  * random subsampling
    * учим с рандомными пропорциями, повторяем
  * Хорошо хранить в k-d деревьях



  * настраивание метрики
    * берём метрику минковского, для расстояний координаты умножаем на веса, двигаем веса

  * Отсутпы:
    * то, насколько похож объект на класс, к которому мы его причисляем.
    * модель рангов на отсупах - многие объекты могу быть удалены. 
    * Нужно оставлять основные и пограничные

  * Поиск аномалий
    * по сути, нам не нужны объекты “не утки”
    * Мы знаем как выглеядт объекты одно класса, про остальных не знаем. Это задача с полуобучением
    * контекстные аномалии
      * мы должны знать, контекст, чтобы понять выборос или нет
    * груповые аномалии - сильно выделяется из остальной выборки
      * Определяем выброс на основе удаления от основных кластеров
        * Объект оказался в месте где гораздо меньше других объектов




**Семинар 1:**

Email будет

Для всех задач:
  * Стринги нумеровать
  * сделтаь shuffle
  * Нужно делать кроссвалидацию (20% на валидацию, т.е. бъем на 5 k), сохраняя пропорции. (каждые класс бъём отдельно, соединяем)

F_1 мера - нормируем точность - чем больше класс, тем меньше повышается точность при угадывании, и на оборот.
среднее отклонение на регрессиях - (y_i - y^*_i)/y_i
дедлайны - через неделю желательно, можно спросить что и как.
Через две жёсткий.

Суть обучения  -найти хорошую K 
Обычно переберём K.

Выбeраем ядро

библиотеки?!?
Weka - для java

Библиотеки нельзя пользовать для настроек алгоритма который изучаем


**Лекция 3: линейные классификаторы**

В метричиских, за счёт метрики, появлялась разделяющая поверхность, граница могла быть сколь угодно сложной.

  * В реальности обычно границы проще - идея строить самую простую границу - прямую (гиперплоскость)
    * (пока не рассматриваем выборки с шумами)

  * Есть обучающая выборка T^l
  * Есть гиперплоскость, всё что ниже - однин класс, иначе другой.
  * sign(f(x, w)) выдаёт {-1,0,1} 0 - очень редко, причилсим его с любому другому классу. если -1 - один класс, 1- другой.
  * Строим прямую, которая хорошо разделяет наши классы. 


Используем потнятие отступа (разница похожести на свой класс, и на другой) (в нашем случае можно использовать знаковое расстояние до прямой)

Отступ - положительный, то это хорошо, елси отрицательный - то скорее всего неправильно классифицировали. 

Эмпиричиский риск - сколько объектов не угадали, т.е. сумма количества объектов, у которых отрицательный отступ. 


Перейдём от комбинаторной функции к задачи оптимизации.

  * Будем суммировать сглаживающую функцию, от отступа.
    * Есть разные сглаживающие функции. 
    * Нам нужны гладкие функции, чтобы можно было брать производные.
      * Можно использовать нейрон макКутча-питса.

  * Для минимизации будем использовать градиентный спуск.
    * Последовательными итерациями. Если просто градиентный спуск, то всё очень долго.
    * Будем использовать стохастический градиент. Будем считать производную только для одной лишнией точки для шага.
    * + будем забывать старые результаты. обычно альфу (коэффициент забывания) берут в районе 1/l
    * Важен порядок выбора объектов (зависит, в какой минимум придём), важна скорость обучения (при большой может просто промахнуться мимо минимума)
    * Правило хебба (дельта правило)
      * Перцептрон розенблата
      * почти тоже самое, с некоторыми особенностями.




Теорема Новикова:
В случае линейно раздилимой выборки, мы сойдёмся в голобальный мимумм стохастическим спуском, за конечное изменение переписывание вектора весов (есть вернхняя оценка), независимо от скорости и способа подачи точек.


  * Эвриситки:
    * Исходные веса можно нулями, но лучше маленькими случайными значениями [-1/2n, 1/2n] 
    * Можно взять много маленьких подвыборок, попробуем из их обучаться на разных весах.
    * Ещё можно пробовать к этому брать несколько разных точек и идти из них. 

  * Как упорядочивать объекты?
    * меремешивать классы
    * давать объекты которые похожи меньше всего. 
    * не давать сильно похожие объекты
    * давать зашумлённые объекты
    * множество запусков мало что дадут.

  * как выбирать длинну шага?
    * выбираем убывающую последовательность скоростей, такую что сумма последовательности до бесконечности бесконечна, а сумма квадратов конечна
    * Скорейший градиентные спуск - выбираем скорость на каждый шаг, приближаюя к максимуму
    * Есть техники для выпрыгивания из локальных мимумов 
      * бросая монетку, в случае зацикливания


  * Регулярицазия
    * вектор w может расскачиваться, будем переобучаться
    * решение: ограничиваем норму
    * очень легко внедряется в код



  * Измерение эффективности
    * таблица контингентности
      * true positive | false positive
      * false negative | true negative
      * часто есть ограниячения на определённые false
        * один тип ошибки часто значительно дороже чем другой
          * если пропускаем террориста то это дорого, а если отправляем гражданина на доп. осмотр, это нормально
      * Recall
        * TPR
        * TP/P
      * Specificty 
        * SPC = TN/N
      * Precision 
        * PPV
        * TP/(TP + FP)
      * Accuracy
        * ACC
        * TP + TN/ (P+N)
      * Часто один класс сильно меньше другого
        * нужно это учитывать, иначе не будет понятно, какой точнее
    * F-мера
      * F_b = (1 + b^2) * Precision*Recall / (b^2*Precision + Recall)
      * часто берут b = 1
      * но по хорошему её нужно выбирать
    * ROC-curve
      * Есть свободный член w_0
      * прямая sensitivity / 1-specificyty
      * чем больше похожи на прямоугольный угол, тем лучше, 
      * чем больше на диагональ тем хуже
      * эвристика - Чем больше площадь под кривой тем лучше
        * мера AUC - Area Under the Curve
    * Если много классов?
      * обычно один против всех и объединяем
        * как - потом
      * Иногда строим дерево 
        * отделяем наличие рака, от его разновидностей
        * дальше отделяем разновидности

**Практика 2:**
Нужно нормировать фичи
Регуляризация - пока не будем пользоваться, но будем позже.
Вводится как функция штрафа
Линейна регрессия


**Лекция 4:**
**SVM - Машина опорных векторов.**

Топовый алгоритм машинного обучения.

Многомерное пространство.
Хотим провести гиперплоскость с максимальной шириной разделяющей полосы.

Разделяющая полоса - все точки между прямыми паралельными, разделяющей прямой, и проходящими через ближайшие ей точки разных классов. На границе разделяющей полосы находится минимум три объекта. Если два - то можно повернуть её, так, что будет три.


  * Прямая максимизирующаяя минимальный отступ, будет устойчива, говоря языком мат. статистики.
  * Поэтому считаем, что чем больше отступ, тем лучше - хотим его максимизировать.
    * Давайте нормализуем отступы. Т.е. сделаем так чтобы максимальный минимальный отсуп был равет 1. Т.е. ширина разделяющей полосы будет равна 2м.
    * Через это переходим к минимизации квадрата нормы вектора w, с ограничением на пороги для каждого вектора.
    * В условии заложено что у нас будет 3 точки на краях.
    * Задача квадратичного программирования. (Стандарт для решения  алгоритм SMO).

  * Для не линейно разделимого случая, решений не будет.
    * Поступим стандартным способом: добавим релаксацию.
    * Если релаксацией становится большой, то будет много решений. 
    * Минимизировать отдельно релаксацию, а потом W, сложно. Давайте минимизировать W + sum(e_i)* c, где c настраиваемый коэффициент, который будет означать важность вклада релаксации.
    * Дальше мы выписываем в явном виде решение задачи. Это магия, и её вообще мало кто рассказывает. 

  * типы объектов
    * лямбда = 0, значит не учитываем
      * Объекты которые классифицируется хорошо, lamda = 0 и они просто ни как не учитываются, их можно выкинуть.
      * Может значительно уменьшиться количество объектов
    * 0 < lambda < C
      * опорные вектора
    * lambda = C
      * вектора влияющие на границу


  * Kernel trick.
    * Почти всегда выборка не линейно разделима, однако можно добавить признаков, так, чтобы она стала линиейно разделима.
      * Т.е. если  можно было хорошо разделить точки кругом в центре 0,0. то давайте вынесем в ось Z расстояние до центра. У нас будет что-то вроде конуса, и плоскость паралельная Oxy хорошо разделит наши точки.
    * Если для каждого объекта сделаем “ядрышко”, и добавим признак похожести на него, то похожие на него объекты будут хорошо линейно разделимы.
    * Ядра как и скаляр, в определяют насколько похожи объекты. 
    * Т.е. заменяем скаляр на ядро, и у нас появляется больше возможностей. Это реально, потому что у нас остаётся небольшое число суппорт-объектов, хотя это не реально для метрических классификаторов.
    * У нас стоит задача синтезирования ядра, поэтому у нас немного отличаются определения.
    * Есть стандартные наборы ядер.
      * Гаусово де-факто стандарт
      * потом полиномиальное
      * потом гаусово
    * Есть множество способов синтеза ядер.
      * Но не понятно, что делать. Проблема выбора ядра актуальна.

  * Достоинства
    * небольшое количество опорных обьектов
    * любая разделяющая поверхность
    * универсальное решение

  * Проблемы:
    * Шум это большие проблемы
      * шумовые объекты будут суппорт векторами
    * Ядро выбрать
    * выбирать константу С
      * есть стандартный набор констант
    * нет выбора набора признаков


  * Регуляризация
    * Чтобы не переобучаться 
    * легко делается на W
    * можно делать регуляризатор на лямбды, но не традиционно.
    * LASSO  позволяет отбирать признаки
    * Support Feature machine 
      * позволяет выбирать признаки
      * вырождается в регуляризацию W



**Лекция 5:**

**Вероятностные классификаторы.**

Метрические и линейные классификаторы. Они понятны. Вероятностные менее понятны.
  * Вспоминаем формулу байеса.
    * Если тест говорит что человек болен, и прав 95% вероятностью, а болезнь распростронена среди 1%, то при положительном тесте вероятность болезни 16%


  * допустим у нас есть признак рост, и объекты юноши и девушки.
    * есть гистограмма распределение роста.
    * Хотим угадывать с наибольшей вероятностью пол по росту. Юноши в среднем выше, значит если будем объекты с большим ростом считать юношами,  а с низким девушками, то вероятность ошибки будет меньше 1/2.

  * Неизвестна не целевая функция, а неизвестное распределение
  * Задача: найти алгоритм, которым минимизирует вероятность ошибки
    * Будем говорить не про модель алгоритмов,  а про семейства распределений. 
    * Т.е. будем искать распределение из определённого семейства


  * Будем брать независимо из обучающей выборки (объект, ответ)
  * Есть функция разбивающая Х на y  областей, A_i
    * ошибка, когда мы не угадали с областью объекта.
    * Есть вес ошибки. Обычно вес неугадывания равен



  * Генеративная модель данных.
    * У нас есть коробки и есть объекты. (классы и объекты)
    * процесс генерации данных разбивается сначала на выбор класса, потом на то, что делаем с объектом.

Pr(Y) - распределение класса
p(X,Y) = p(x)Pr(y|x) = Pr(y) p(x|y)
Pr(y|x) - нужно узнать. 

Остальное можем попробовать узнать, поэтому будем решать по второй схеме. От обратного.
Вероятности классов обычно знаем, иначе можем восстановить.
  * Две задачи
    * Восстановление плотности вероятности
      * нужно понять устроено пространство 
      * как распределены классы
      * как распределены объекты по классам
    * минимизация среднего риска
      * обычно легче. Просто выбираем наиболее вероятный класса.
      * Принцип МАР (maximum a postariori probability)
        * Выбираем класс где объект наиболее вероятен

  * Пример
    * Допустим мы после войны.
    * Юношей меньше чем девушек. Нужно учитывать это.

  * Чуть более сложная задача, когда у нас разные стоимости ошибок.
    * Может быть критично, что ошибка на девушке больше нам стоит, а на парне меньше. это тоже нужно учитывать.
    * Потери от попадания в спам не спама выше, чем не определение спам сообщения

  * Классификатор который минимизирует риск с учётом веса ошибок, назыается оптимальным байесовским классификатором. 
    * Алгорим может работать хуже, потому что мы восстанавливаем вероятности, и они могут оличаться от реальных. 
    *   Поэтому SVM часто работает лучше байесовсовского классификатора.

  * Разделяющая поверхность - поверхность на которой вероятности попадания в граничащие классы равны.

  * Как получать вероятности
    * можно взять дополнительную информацию из реального мира
    * можно просто брать распределение обучающей выборки
      * выборка часто смещена и мы не знаем как


Внезапно, это задача обучения без учителя.

Нужно понять, какое распределении лучше подходит под эти объекты. Этим матстат и занимается. В матстате куча условий, тут у нас тоже будет куча предположений. 


В случае одномерного распределения. 

  * не параметрическое восстановление плотности
    * можно фиксировать окно, и усреднять вероятности в окне. 
    * Вместо окна можно использовать ядро фиксированной ширины.
    * оценка парсзена-розенблатта
    * какое-то значение с шапочкой - значение которое пытаемся восстановить.
    * Усложняем ещё. Берём произведение разных ядер.
    * можно брать многомерное ядро
    * По сути приходим к метрическим классификаторам. 



  * наивный байесовский классификатор 
    * считаем что признаки независимы
    * бывает не особо часто, но случается
    * скажем классификация текстов по вхождению слов или n-грамм
    * работает за счёт того, что ошибки в разных классах друг друга компенсируют 


  * параметрическое восстановление вероятности
    * будем пытаться выбирать распределение из какого-то семейства как в матстате. 
    * манимизируя эмпирический риск, максимизируем правдоподобие.
    * выбираем то распределение, которое больше нам подходит
    * принцип совместного максимального правдоподобия
      * есть выборка военнослужащих
      * парметризуются средним ростом и дисперсией
      * средний рост как-то распределён по группам
      * генеративнам модель
        * генерим средние рост
          * гипер распределение с кипер параметрами
          * могут быть пожарники с пуасоновскими распределениями
        * генерим выборку
        * делаем это нормально 



Если будем считать, что веса распределены нормально, то квадратичные  штрафы очень похожи на регулялизацию.

  * два частных случая
  * ограничения на вид описывание 
    * нормальный дискриминантрый анализ
      * предположим что объекты распределены нормально в многомерном пространстве
      * теорема
        * матрица ковариации задаёт направление вектора на котором посттоен элипсоид гаусова распределения. 
        * если матрицы ковариации равны, то элипсоиды сонаправлены
        * если матрицы ковариации равны, то раделяющяя поверхность гиперплоскость, иначе квадратична




  * линейный дискриминант фишера
    * устойчив к шумам
    * легко переобучается
    * сейчас ипользуется не очень часто
  * Расстояние махланобиса





  * логистическая регрессия
    * рассмотрим класс распределений - экспонентные
      * в него входят все основные и не только.
      * Коши например нельзя выразить.
    * Если распределение экспонентное и ещё что-то то классы линейно разделимы 
    * Мы прошли от вероятносных предпосылок, следали преход между вероятносным и эмпирическим риском
    * получили функцию логарифмических потерь
    * логарифмическое приближение весьма хорошее
      * производную легко считать
      * градиент  просто считается, значит и градинетный шаг
      * если всё хорошо, то ничего, а если плохо то вычитаем ошибку
      * правило хебба мы получили сглаженным. 


**Лекция 6:**

**Регрессия**

  * Есть множество обьектов и значений.
  * Y \subset R  !!!!!!
  * Пердполагаем, что функция зависимости линейна от своих аргументов
  * Есть тренировочная выборка
    * Заданые значения целевой функции зависимости на них

  * Нужно установить зависимость.
    * Функция из объектов в значения
    * Без шума скучно - просто интерполяция.
  * Будем работать с нормальным шумом. 

Есть нормальное распределение шума для каждого объекта. Если предпологаем это, то можно с помощью простых математических преобразований получим, что метод наименьших квадратов работает лучше всего.

Применяется где попало, и где попало он работает неплохо. Потому что для других распределений тоже как-то нормально работает и в реальном мире обычно шум близок к нормальному.

  * не прараметрическая регрессия
  * Идея
    * чем ближе объект к объекту из тренировочного множества
      * тем ближе должен быть результат функции зависимости
      * На основе этого просто построим функцию потерь
  * Будем восстанавливать регрессию через ядра 
  * С помощью ядер сгладим занчения данные на тестовой выборке
    * При некоторых предположениях регрессия будет сходится к матожиданию, что нам и нужно.
    * обсуждение
      * сильно влияет ширина окна на гладкость
      * выбор ядра почти не влияет
      * чувсвтителен к шуму
      * h влияет на качество приближения
      * k можно менять и улучшать
      * по числу соседей в этом случае лучше не смотреть
  * Найдём вид функций, которые хотим выбирать 
  * параметрическая регрессия
    * линейная регрессия
      * функция регрессии линейна
      * можно выбирать признаки самому так, чтобы зависимость от них была линейна
      * давайте выберем x, x^2, x^3, sin(x), ln(x), sqrt(x)
      * если угадаем признаки то пространство будет линейно зависить от этих функций
      * решается с помощью нормлаьной системы уравнений

  * SVD - Снигулярное расзложение матрицы
    * сильный инструмент для машинного обучения
    * матрица преоразуется в прозиведения трёх матрици с крутыми свойствами
    * из за этого, куча диких вычислений с матрицами просто считается через сингулярное разложение
    * Правильный способ считать регрессию - скормить матририцы мат. пакету для получения разложения, а потом это использовать

  * регуляризация
    * штрафуем модель за то, что она сложная
    * штрафуем за большие веса
    * позволяет избежать переобучения
    * гребневая регрессия
      * добавляем к диаголнали одинаковую константу = тау, чтобы сделать матрицу хорошо обусловленной, обратную более устойчивой
      * По сути квадратичный регуляризатор
      * баланс тау нужно искать
      * ответ становится хуже, но мы уменьшаем переобучение

  * LASSO
    * обеспечивает выбор признаков
      * ограничевается число коэфффициента. Чем больше штраф, тем больше признаков нулевых. 







**Семинар 4:**

  * для SVM
    * возьмём дополнительные знания из дополнительного пространства
    * Дополнительные экспертные данные
    * тот же датасет, чипсы
    * нужно брать хорошие ядра.
    * Т.к. эллипс, нужно вять ядра x, y, x^2, y^2, xy
    * можно побаловаться с ядрами, рассказать про ядра, но не обязательно.

  * С баесом веселее
    * Есть почтовые сообщения
    * фичи: title, все стринги в интах
    * боди: тоже только больше
    * можно взять title и body попробовать померить
    * можно добавить в обучающую выборку письмо со всеми словами
    * нужно разделять по словам. 
    * Попадание в спам хорошего это очень плохо, цена ошибки на попадание спама в обычные письма не так велика.
    * лямбды для регуляризации - это очень нужно.
    * допустим разница в 25 раз. это можно 

**Лекция 7:**
**Нелинейная регрессия.**


  * дана модель зависимости
    * зависит от свободной переменной и \theta \in R^n
    * предполагается что от  \theta зависит не линейно
  * Нужно подобрать \theta 
  * Хотим минимизировать взвешенную сумму отклонений модели зависимости на тестовой выборке




  * В случае линейной регрессии мы искали линейную комбинацию признаков. Нужно было думать, какие призники добавить, чтобы можно было выразить зависимость через линейную регрессию.
    * Тут такой проблемы нет

Если будем считать что функция дважды гладкая, то можно минимизировать методом градиентного спуска. 

Порядок метода оптимизации: какой степени производную нужно взять в методе.
Нужно использовать методы больших порядков в этом случае.

  * Метод Ньютона-Рафсона
    * Метод градиентного спуска, но с дополнительными знаниями.
    * Нужно считать Хессиан каждый на каждом шаге
      * Хессиан - матрица, вторая производная
      * Является методом второго порядка
      * Очень дорого
    * Нужно считать производные и брать обратную матрицу.

  * Квази-ньютоновские методы.
    * Используем приближения Хессиана, и другие трюки, чтобы не считать обратную матрицу.
    * Метод ньютона-гаусса
      * Главная идея - линеализая Хессиана
      * Вводим новую матрицу, забиваем на подсчёт Хессиана,  получаем линейную регрессию.
      * Т.е. получается, что нужно решать серию линейных регрессий.




  * Была логистическая регрессия. 
    * Попробуем переосмыслить.
    * Логарифмическая функция потерь
    * К ней применяем метод ньютона-равсена
    * Не хотим его явно обсчитывать.
    * Всё весело. Получаем линейную регрессию. 
    * Чем выше значение sigma_i на объекте, тем больше мы сомневаемся в его классификации. Парабола с максимумом в 1/2 и нулями в 0 и 1 



Часто непонятно из какого пространства функций, нам брать функции.
Вместо изменения функций будем изменять признаки.
Будем делать покоординатный спуск по признакам.
Итеративный процесс.
Останавливаемся когда ничего не можем улучшить.
На каждом шаге нужно сильно учитывать, чтобы не переобучились.
Самый распростронённый способ, статистически

  * Методы групового учёта аргументов.
    * Чтобы не переобучастья, можно потихоньку увеличивать сложность обучения.
    * Общая коцепция:
      * начинаем с простого класса функций. Линейных или вроде того.
      * получаем примерно лучшую параметризацию
      * Потом начинаем брать куски полинома Колмогорова-Габора
      * Много критериев, чтобы понять, переобучились или нет.

  * выбросы, outliers (можно понимать как шум)
    * Есть пара тройка способов для бопрьбы с этим.
      * обучаемся на всех объектов кроме одного, на оставшимся смотрим ошибку 
        * потом учитываем эту ошибку
      * Устойчивая регрессия
        * в качестве функции потерь возьмём функцию потерь Мешалкика (1 - epxp(x^2))


**Лекция 8:**
**Ансамбли**
Лекция была пропущена, так что тут мало 

  * Слабая обучаемость
    * за полиномиальное время можем найти алгоритм с accuracy > 50%
  * сильная обучаемость 
    * за полиномиальное время можем найти алгоритм с accuracy любой величины
  * Теорема:
    * Сильная и слабая обучаемость эквивалентны
    * Из алгоритмов получаемых в ходе слабого обучения можно делать композицию и добиваться сильной обучаемости

  * Пример
    * Имеем много независимых классификаторов с небольшой точностью больше 50%
    * Используем все
    * Выбираем что выбрало большинство
    * вероятность правильного ответа растёт с числом алгоритмов


  * Проблема:
    * Есть множество объектов и ответов
    * Есть тренировочное множество с даными ответами для них
    * Есть семейство базовых параметризованных алгоритмов
    * Нужно найти (создать) алгоритм с наилучшей точностью предстазывающий ответ по объекту
    * Рассмотрим алгоритм как взвешенную сумму алгоритмов семейства
    * будем оптимизировать градиентым спуском
    * Сглаживать можно различными функциями
      * на этом основаны разные алгоритмы
    


Бустинг - Выбираем алгоритмы из подмножества, даём веса объектам и алгоритмам, добавляем алгоритмы пошагово, чтобы это компенсировало ошибки предыдущих

Стекинг - обучем много разных алгоритмов независимо, их результаты подаём как фичи на вход другим алгоритмам


  * Синтезирование случайных алгоритмов
    * Эмпирические наблюдения
      * Веса алгоритмов не очень важны для достижения равного отступа
      * Веса объектов не очень важны для достижения разницы
    * Синтезирование
      * Bagging: обучаемся на подвыборках равной длинны
      * Random subspace method: обучаемся на подмножествах фичей
      * Фильтрация: 



**Лекция 9:**

**Логистические классификаторы и деревья решений**

Пример: 
Предикторы в реальной жизни: зелёный свет светофора, 
Если переходить на зелёный, больше вероятность что не собьют 
Если есть машины, то чаще сбивают.
так же правила когда нет светофора.
Есть иксключения.
Потом комбинируем простые правила и решаем по ним что делать.
Понятние концепта: 
Предикат на множестве. Результаты: да, нет, не знаю.

  * Хотим интерпретируемости концептов.

    * может формулироваться на нормальном языке
    * Зависти от меньшего числа фич
  * Информатируемость

    * хотим большое число True Positive = p
    * Меньше чилсо False Positive = n
    * Это многокритеальная оптимизация, это сложно
    * нужно свернуть эти p и n в одну функцию, и максимизировать (минимизировать) её.
  * Эпсилон дельта правила
    * Фиксируем эпсилон и дельта
    * от через них выражаем критерий того, что правило нам подходит
  * Есть энтропия для общего распределения, и энтропяи того, на что разбилось правило
    * вводим функционал оценки качества правила основываясь на энтропии
    * IGain
  * синдром
    * совокупность симптомов
    * Связный переход между коньюнкцией и дизъюнкцией
    * Пороговая функция - срабатывает, если есть d симптомов из синдрома
  * Полу плоскость
    * если можно как-то более менее разделять
  * Шар
    * если в терминах близости
  * Парето оптимальное множество
    * множетсво домирирующих точек
    * Доминирующая точка
  * На основе правил строим ансамбли




  * Деревья решений

    * Чем выше высота, тем сложнее алгоритм. 
    * Мера переобучения
    * Можно ограничивать сложность модели
    * можно потом делать Pruning, т.е. подрезку
    *



**Нейронные сети:**

Правило хебба:

Если нейрон хорошо предсказывает активирование другого нейрона, связь укрепляется, иначе разрушается.

Дельта правило:
Ошибаемся - веса уменьшаются
Угадываем - у


Галушкин - писал русскую книгу по старым наработкам.
Нейрон - сумма входов, плюс константа, разделяющие правило

Любая булевая формула - двухслойная нейровнная сеть.

  * Есть теорема Горбана 
    * При помощисупер позиций можно построить любую функцию
    * Но не понятно, какого размера и конструкции 
    * Строить композиции нейронов которые дают линеный выход - нет смысла строить второй слой.
    * Нужна функция активация, которая добавляет нелинейность


  * Схема нейровной сети
    * на вход фичи и -1
    * от всех входов на все сумматоры веса
      * в случае полносвязной
      * можем делать не полносвязаное
    * выходы от сумматоров на активационные функции
    * выходы от активационных и ещё один -1, на выходные нейроны
      * на последующий слой, если нужно 
    * один выходной нейрон - одна линейная классификация


  * Всё это очень сложно обучать
  * долго не умели
  * градиент в безумномерном пространстве
  * Стохастический градиент - градиент изменяя только один вес
    * каждый шаг
    * есть w -вес
    * берём следующий объект
    * пожем посчитать ошибку и производную

  * делать тоже самое для нейронок очень сложно из за безумномерности пространства
  * Начинаем делать всё последовательно (по слоям?)
  * делаем обратную пропогацию 
    * считаем насколько ошиблись
    * считаем производную функции активации, передаём на следующий слой обратно
    * вектор ошибок даст вектор частных производных, на основе которых изменим веса
  * Алгоритм называется Backpropogation
    * Плюсы
      * эффективность
      * легко адаптируюется для гладких сигма,  L
      * можем найти оптимум раньше чем кончатся объекты
    * Минусы
      * не всегда сходится
      * может застревать в локальных минимумах
      * можем переобучаться
      * нейронный паралич - веса в нейронах ни как не меняются
        * при глубоких сетях
  * Больше чем три слоя появились восем не так давно
  * Ошибки становится нулевыми на глубоких слоях, и глубокие слои не обучаются.
  * Нужно считать производную ото всех, стохастический градиент, за счёт измений на одном объекте, не может изменить это.
  * В сетки добавляют регуляризаторы на веса, чтобы не переподгоняться - 



  * Сложно настраивать структуру сети
    * Число слоёв выбора
      * обычно берём двухслойку, потом увеличиваем количество слоёв пока помогает
    * Число нейронов скрытого слоя




**Лекция по рекомендательным системам:**

<http://www.4ducks.ru/>**
**

  * Данные:
    * Сильные, явные:
      * Виды:
        * унарыне (like)
        * бинарные (like, dislike)
        * числовыне (stars)
      * Мало
      * очень сильны
      * приходится мотивировать это делать
    * стория действий (implict feedback)
      * сильно шумный
      * данных много
    * Social-grapth
      * что у друзей будет часто нравится
    * коммент 
  * Задачи
    * Predict
      * тупо регрессия
    * recomend
      * часто сложно
      * много данных из которых выбирать
    * Similar
      * не персонализированный / персонализированный
      * не сильно развиты
      * делают “на сдачу”
  * Строим рейтинги
    * нормализуем для каждого пользователя
      * три разных метода
        * среднее
        * z-score
        * перцентили
    * user-based KNN
      * Часто забивают на KNN
      * если взять хорошие расстояния, то он много кого порвёт
    * SVD
      * раскладываем в три матрицы, где средняя - диагональная, сингулярыне вектора
      * хороший свойства (лушчие приближения, если брать большие вектора)
      * в 2006 году идея сделать то же самое, но оптимизацией
      * SGD - золотой стандарт, quick-start рекомендательных систем
      *       * алгоритм есть:
        * средний рейтинг
        * есть баейес на пользователя
        * в оптимизации мы получаем скрытые параметры
          * сжатые фичи о пользователе / фильме
          *

      * Alternating Least Squares - 
        * можно делать в онлайне
        * очень хорошо паралелится
      * iALS
        * implicit ALS
        * ALS для неявного фидбека
        * считается за куб от фичей
        * Интуиция
          * работает 
  * Explanation

    * Неплохо бы объяснять пользователю, почему его это может заинтересовать
    * Похожесть считаем на рейтингах
    * Возьмём пользователей которые посмотрели и то, и то.
    * возьмём рейтинги
    * смотрим близость рейтингов пользователей посмотревших и то, и то
    * Можно брать косинусное расстояние
    * Можно выбирать веса с максимальными вкладами - получим
  * Метрики измерения качества
    * Precision, Recall, F_1
    * avarage precision
    * mean average precision
    * NDPM - ranking quality
      * чтобы решать задачу recomend
      * насколько правильно отсортированы
    * **RMSE**
    * Для хороших результатов нужно использовать всё
    * Всё пихаем в ансамбли

SGD
Нужно считать обновлеи одновременно  (не последовательно веса


**EM + PCM**
//Видимо забыл писать конспект на лекции.  Могу что-то написать по презентации.

**Кластеризация:**
Нужно сгруппировать точки. Нет чётко поставленной задачи. Можем группировать совсем по разному

  * Пришло из статистики. 
  * Как только меняем метрику, кластеры становятся совсем иными.
  * Часто не знаем, сколько кластеров нужно
  * Часто хотим понимать связь внутри кластера
  * Примеры задач
    * поиск необычных объектов
    * результаты олимпиады, в них выделяются 
    * Выделение ботов по поведению 
      * выделения кластера ботов
    * есть документы, нужно разбить про темы
  * Примеры кластеров
    * прямо разделимые
    * полоски
    * с мостами
      * создаёт сложностями
    * с шумом
      * создаёт сложности
  * Оценка качества
    * метрики
      * попарные расстояния внутри класса -&gt; min
      * попарные расстояние между классами -&gt; max
      * расстояния от центра кластера -&gt; min
      * расстоянием между центрами -&gt; max
    * можно придумать метрику, что у нас неправильно разделится на кластеры
    * Каждая метрика выбора качества кластеризации где-то лажает


  * Виды алгоритмов
    * графовые
      * постой из з 50х
        * удаляем самые длинные рёбра
        * пока число компонент связности не станет в нужном нам интервале
      * Строем минимальное остовное дерево
        * удоляем K-1 самых длинных деревьев
        * получим K компонет связности
      * FOREL properties
        * покрываем шарами 
        * берём точку, обозначаем за центр шара
        * следующий центр будет центром масс покрытых точек
        * таким образом можно покрыть сложную структуру, потом запустить на центрах другой алгоритм кластеризации
          * хорошо работает на лентах
          * так себе работает с шумом
        * две степени свободы
    * Иехархические алгоритмы
      * можно считать что всё кластер
        *  будем разделять
      * можно считать все по кластеру
        * будем агломирировать
      * алгоритм Ланса-Вильямса
        * m clusters
        * repeat m-1 times
          * соеденяем два ближайших кластера
          * пересчитываем расстояния между кластерами
        * Расстояние сложная формула, линейная комбинация четырёх расстояний. Расстояние ланса вильямса
        * Можно получать разные расстояния
          * между билижайшими
          * между наидалёкими
          * среднее между точками
        * Иерархии сложно сравнивать
          * вроде все адекватно работает, но непонятно что лучше
        * Дендрограмма
          * структура отображающая соединение в кластеры
          * разрезав её по определённой высоте можно получить нужное число кластеров
          * строит расщипить по моменту объеденения самых далёких кластеров |R_{t+1} - R_t|
        * Хотим от иерархии некоторых свойств 
          * монотонность
            * из рассмотренных не работает только для расстояния между центрами
      * EM подобные
        * k mean
          * выбираем случайно k центроидов из выборки
          * получаем  k кластеров, выбираем центр у кластера (уже не объект центра)
          * относим точки к этим новым центрам
          * стохастический
            * зависит как центроиды изначально выбирали
        * с-means
          * у каждой точки будут степени принадлежности
          * случайно раскидываем центры кластеров
          * расчитываем степени принадлежности к кластерам
          * чем выше d тем жесче кластеризация
            * насколько острые степени принадлежности
            *

  * _практически к каждому алгоритму бывают модификации _
  * частичное обучение

**Обнаружение асоциативных правил:**

пример: куча неразмеченных данных, хотим выделить закономерности

  * частые последовательности
  * условные вероятности
    * как часто люди покупают мыло, когда купили верёвку
    * взяли паттерн с лазерным мечём, посмотрели на частые паттерны другие
  * алгоритм априори
    * речь про частично упорядоченные множества     
    * если раделить множество на подмножества, и сделать рёбра по включению, пустое множество убдет соеденять единичные множества
    * получится решётка на рёбрах гипер куба
    * элемент встречается не чаще, чем каждый меньший его
    * идём по решётке из пустого множества, откидывая все не частые, и все кто их включает 

**Советы в анализе данных**
  * Синтез фичей
    * Самый важный этап для сырых данных
    * Синтезируем фичи вроде
      * x^2, x^3, ln(x), 1/x, sin x, e^x ...
    * Бинаризуем категориальные фичи
    * Майним зависимости и шаблоны времени и бинаризуем их 
    * Пробуем бинаризировать числовые фичи
    * Майним текстовые фичи
    * Объеденяем фичи, которые кажутся связанными
    * Создаём фичи специфичные задаче

  * Препроцессинг данных
    * Отсутсвующие значения 
      * Забываем об объектов с отсутсвующими значениями
      * Забываем о том что они есть
        * некоторые алгоритмы справляются 
      * Пробуем заполнять рандомно
      * Пробуем заполнять разумно
        * MCMC sampling
      * Используем специальные алгортимы обработки таких неточностей

  * Фильтрация шума 
    * Важно
    * Много подходов
    * Может быть сделано несколько раз в течении анализа

  * Нормализация фичей
    * Важно для большинства алгоритмов
    * Нормализация фичей
      * сжатие/растяжение на [0;1]
    * Регуляризация
      * Среднее 0, Среднеквадратичное отклонение 1

  * Выбор ядер 
    * Выбор ядра = выбор растояния
    * Хороший выбор ядра может решить проблему
    * Нет универсальных эвристик
    * Может быть автоматизировано

  * Кластеризация объектов 
    * Может быть полезным объеденить какие-то объекты в небольшой кластер
    * Или же может быть полезным добавить кластер как фичу

  * Синтез меток 
    * Выбрасываем редкие классы
    * Объеденяем классы или строим иерархию
    * Числа -> Ранги -> Категории
    * Разбиваем сложные метки на простые
    * классификация  против остальных

  * Сокращение размерности, выбор фич
    * Пробуйте если фич много
    * Пробуйте в любом случае
    * Могут быть применены быстрые и не очень быстрые алгоритмы выбора фич 
    * Некоторые алгоритмы (RF) могут осуществлять выбор фич самостоятельно
      * Использовать с умом 

  * Извлечение фич
    * Пробовать для небольших подмножеств фичей
    * Пробовать для визуализации
    * Пробовать для сигналов
    * Пробовать для разреженных данных

  * Визуализация
    * Важно для понимания данных
    * Отрисовывать каждый шаг
    * Отрисовавать результат для анализа
    * Использовать сокращение размерности для визуализации
    * Визуализировать данные для одной фичи

  * Модели
    * Выбор модели
      * Пробовать все возможные модели
      * Пробовать модели подходящие для задачи
      * Выбирать автоматически
      * Выбирать модели зарекомедовавшие себя для похожих задач
      * Использовать глубокие нейронные сети
    * Комбинирование моделей
      * Комбинировать все постороенные модели
      * Использовать Стекинг
      * Комбинировать некоторые модели
      * Посроить нейронку с на выходах моделей
      * Не забывать про переобучение

  * Тюнинг Параметров
    * Может быть важен, а может и нет
    * Жадный поиск
    * Случайный обход
    * Оптимизация параметров

  * Анализ
    * Достаточно ли данных?
    * Как распределены выборки?
    * Что известно о фичах?
    * Что является метрикой успеха?
    * Что требует моя модель?
    * Переобучена ли модель?
    * Надёжна ли модель?
    * Важна ли модель?

  * Специальные случаи
    * Предсказание временных рядов
      * Можно понимать как проблему множественной регрессии
      * Обычно функция потерь убывающая от времени
      * Специальные методики решения
      * Глубокие сети
      * Важно найти подходящий переод масштаба (может не существовать)
    * Декодирование сигналов
      * Видео, изображения, речь, звук
      * Специфичная предобработка и трансформация
      * Обычно несколько интерпретируемых фич
      * Много фильтров и подходов к работе с фичами
      * Глубокие сети - вершина искуства
      * Если используется как дополнительная информация, то ковертировать в текст 
    * Обработка текста
      * Обычно языко зависима
      * Много методов с учителем и без
      * "Bag of words" парадигма, POS-taging и майнинг правил
      * Много проблем от анализа отношения, до понимания языка
      * Глубокие сети









